# Planet

## Description
This project implements multithreaded A* to navigate a convex polygon world, which the user can define during runtime. It uses SDL2 for its rendering. The name is due to the etymology of "planet", which in greek meant traveller. How does a planet move? A star! It's too funny to pass on.

## How to use
_Left-click_ anywhere to start drawing a polygon with a vertex at the position of the cursor. Each subsequent _left-click_ will define the position of the next vertex. Press _return_ to enter the polygon into the world, or _escape_ to discard the polygon. The application will not allow you to draw a concave polygon, or one that contains the "planet" or goal, or intersects an already existing polygon. If you _left-click_ a polygon in the world, it will be selected. _Escape_ deselects it, while _delete_ removes it from the world. _Right-click_ to place the goal at the position of the cursor. You can also change the number of threads that the A* algorithm is run across, by press the _up_ or _down key_. The title will reflect this number, which is initially is 1.

## Promemoria
My goal for this project was to challenge myself by using C++ features and patterns that I previously did not grasp. I wanted the C++ to be modern, which is why it requires C++20, and efficient. I tried doing things a certain way and would like to reflect on the different aspects of my code.

### Macros
I used macros, which as I understand it is a cardinal sin. Normally, I would not use them, but for this specific use case, I like the strategy. I wanted a nice way of detecting errors in my code, and so I used exceptions. Another cardinal sin. So, I thought, maybe I'll just throw if it's in debug mode. So I put #ifdef blocks in which I threw the exception, and else I simply returned. This was good, as it allowed my to test things in debug mode and it would appropriately tell me what the issue is and then run it in release when I want the performance. However, the in-situ preprocessor directives were ugly. So instead I wrote a macro which will throw with a given message if _DEBUG is defined, else the macro is defined as nothing. This is quite a neat pattern I think! I also could add a NOEXCEPT_IF_NOT_DEBUG macro which will do what it says on the box. However, in order for exceptions to really work as intended I needed to catch them. So I wrapped the whole program in a try/catch block, conditionally. Which meant I defined a TRY_IF_DEBUG macro which opened a scope. The matching CATCH_IF_DEBUG had to begin by closing it. Even though this has already set me to far down the path to C++ hell, I'm still not ever going to do that sort of thing in a macro again, cause it really breaks the language. I also need to mention my COMPARE_EXECUTION_POLICIES macro, which records the number of times each execution policy is fastest for the passed algorithm. The use case is good, however the implementation means that the caller must replace the policy parameter with the word "policy", which the macro defines. This is ugly and scary and bad.
In general, I think macros can be useful in this pattern of differentiating the debug and release (or other) modes of one's application, however the particular implementation I went with in this project was not the greatest. And concerning performance comparisons, I think one is better off using some pre-existing tools to benchmark, or atleast make a nicer macro than I did.

### Threading
The A* implementation should not have been multithreaded, is my conclusion. Multiple threads do give a performance boost, but only if the world is sufficiently complex. The amount of synchronization really bottle-necked it. I thought, since I needed to make sqrt calls for every heuristic evaluation, it would be worth it but it simply wasn't. Not only was the performance not the greatest, but it needlessly complicated the solution. The whole idea is that multiple nodes can be handled in parallell. Immediately there is synchronization, as a mutex needs to guard the fringe (the priority queue of nodes to consider). This means that nodes with lower priority are considered before/concurrently those with higher, which basically opens a can of worms. Basically, when a node is discovered it's not sure whether its path is the optimal path. So, if the node is discovered again, from a shorter path, it needs to be put back in the fringe. It may be that the goal is discovered from a suboptimal path, which means the algorithm needs to keep running until all nodes that potentially could have a shorter path are all explored and the top of the fringe has a worse score than the best found path. So, the synchronization meant an increase in space, time (often) and code complexity. Threads, I've come to realize, should aim to run independent processes. I do feel as though I've come to terms with threads a little, altough there is much for me left to explore with threading in modern C++. I did however find that semaphores are a really neat way to synchronize flow between threads.
